# ğŸ˜ƒ Emotion Recognition from Facial Expressions and Text  

![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.12-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Platform](https://img.shields.io/badge/Platform-Windows%20%7C%20Linux-lightgrey.svg)

## ğŸ“ Emotion Recognition Project Structure

emotion_detection_project/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                         # Project documentation (you just created this)
â”‚
â”œâ”€â”€ ğŸ§  models/                           # Trained models for both modalities
â”‚   â”œâ”€â”€ image_emotion.h5                 # CNN model for facial emotion recognition
â”‚   â””â”€â”€ text_emotion/
â”‚       â””â”€â”€ pipeline.joblib              # Trained NLP pipeline for text emotion classification
â”‚
â”œâ”€â”€ ğŸ“‚ data/                             # Datasets used for training
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â””â”€â”€ fer2013/
â”‚   â”‚       â”œâ”€â”€ train/
â”‚   â”‚       â”‚   â”œâ”€â”€ angry/
â”‚   â”‚       â”‚   â”œâ”€â”€ disgust/
â”‚   â”‚       â”‚   â”œâ”€â”€ fear/
â”‚   â”‚       â”‚   â”œâ”€â”€ happy/
â”‚   â”‚       â”‚   â”œâ”€â”€ neutral/
â”‚   â”‚       â”‚   â”œâ”€â”€ sad/
â”‚   â”‚       â”‚   â””â”€â”€ surprise/
â”‚   â”‚       â”œâ”€â”€ test/
â”‚   â”‚       â””â”€â”€ validation/
â”‚   â”‚
â”‚   â””â”€â”€ text/
â”‚       â”œâ”€â”€ train.txt                    # Training data (text + emotion)
â”‚       â”œâ”€â”€ val.txt                      # Validation data
â”‚       â””â”€â”€ test.txt                     # Testing data
â”‚
â”œâ”€â”€ ğŸ§© src/                              # Source Python scripts
â”‚   â”œâ”€â”€ train_image.py                   # Trains the CNN model on FER2013 dataset
â”‚   â”œâ”€â”€ train_text.py                    # Trains the text emotion classification pipeline
â”‚   â”œâ”€â”€ webcam_infer.py                  # Optional script for direct webcam testing
â”‚   â””â”€â”€ multimodal_server.py             # Core backend server for browser communication (no Flask/FastAPI)
â”‚
â”œâ”€â”€ ğŸŒ web_demo/                         # Frontend web files (user interface)
â”‚   â”œâ”€â”€ index.html                       # Beautiful sky-blue themed UI (text + webcam detection)
â”‚   â””â”€â”€ assets/                          # (Optional) for CSS, JS, or icons (if needed later)
â”‚
â”œâ”€â”€ ğŸ§° venv/                             # Virtual environment (Python dependencies)
â”‚
â”œâ”€â”€ ğŸ“œ requirements.txt                  # (Optional) List of required dependencies
â”‚
â””â”€â”€ âš™ï¸ .gitignore                        # (Optional) Ignore venv, __pycache__, etc.

---

## ğŸ§  1. Project Title and Description

### **Emotion Recognition System (Facial & Text-based)**  

This project detects human emotions from **facial expressions (via webcam)** and **text input** using a combination of **deep learning (CNN)** and **machine learning (NLP pipeline)** models.  
It provides real-time emotion analysis with a beautiful, responsive web interface â€” without using Flask or FastAPI.  

#### ğŸ¯ **Purpose**
To create an AI system that understands human emotional states for use in:
- Human-Computer Interaction (HCI)
- Sentiment-based feedback systems
- Smart education and healthcare systems

#### âœ¨ **Key Highlights**
- Real-time facial emotion detection ğŸ¥  
- Text emotion detection ğŸ’¬  
- Confidence rings and emoji indicators ğŸ˜ƒğŸ˜¢ğŸ˜¡  
- Emotion history tracking with clear option  
- Sky-blue, dark/light mode UI ğŸŒ—  

---

## ğŸ“‘ 2. Table of Contents
- [1. Project Title and Description](#-1-project-title-and-description)
- [2. Table of Contents](#-2-table-of-contents)
- [3. Installation Instructions](#-3-installation-instructions)
- [4. Usage Instructions](#-4-usage-instructions)
- [5. Features](#-5-features)
- [6. Technologies Used](#-6-technologies-used)
- [7. Contributing Guidelines](#-7-contributing-guidelines)
- [8. License](#-8-license)
- [9. Credits](#-9-credits)
- [10. Contact Information](#-10-contact-information)
- [Known Issues](#known-issues)
- [Future Plans](#future-plans)

---

## âš™ï¸ 3. Installation Instructions

### ğŸ§© **Prerequisites**
- Python 3.8 or higher  
- Camera access for facial detection  
- FER-2013 dataset for images  
- Kaggle text emotion dataset  

---

### ğŸ§  **Setup Steps**

```bash
# 1ï¸âƒ£ Create project environment
python -m venv venv

# 2ï¸âƒ£ Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux / macOS:
source venv/bin/activate

# 3ï¸âƒ£ Upgrade pip and install dependencies
pip install --upgrade pip
pip install numpy pandas opencv-python matplotlib scikit-learn joblib tensorflow==2.12
pip install pillow Werkzeug aiohttp
```

---

## â–¶ï¸ 4. Usage Instructions

### ğŸ“ **Dataset Structure**
```
data/
â”œâ”€â”€ images/
â”‚   â””â”€â”€ fer2013/
â”‚       â”œâ”€â”€ train/
â”‚       â”œâ”€â”€ test/
â”‚       â””â”€â”€ validation/
â””â”€â”€ text/
    â”œâ”€â”€ train.txt
    â”œâ”€â”€ val.txt
    â””â”€â”€ test.txt
```

---

### ğŸ§  **Training Models**

```bash
# Train CNN on FER-2013 images
python src/train_image.py

# Train NLP model on text emotions
python src/train_text.py
```

âœ… Creates:
```
models/
â”œâ”€â”€ image_emotion.h5
â””â”€â”€ text_emotion/
    â””â”€â”€ pipeline.joblib
```

---

### ğŸš€ **Start Backend Server**

```bash
python src/multimodal_server.py
```

You should see:
```
Loading models...
âœ… Server running at http://localhost:8000
```

---

### ğŸŒ **Open Web Interface**
Visit:
ğŸ‘‰ [http://localhost:8000](http://localhost:8000)

---

### ğŸ’¬ **Text Emotion**
- Type text (e.g., *"I feel amazing today!"*)  
- Click **Analyze Text**  
- View:
  - Predicted emotion with emoji ğŸ˜  
  - Confidence ring  
  - Probability bars  
  - Entry in **Emotion History**

---

### ğŸ“· **Facial Emotion**
- Allow webcam access  
- Click **â–¶ï¸ Start Live Detection**  
- Watch real-time facial emotion recognition  
- Logs each detection to **History**

---

### ğŸ§¹ **Manage History**
- All detections (text & image) are logged with timestamp  
- Click **ğŸ§¹ Clear History** to remove them  

---

## ğŸŒŸ 5. Features

| Feature | Description |
|----------|--------------|
| ğŸ’¬ Text Emotion Detection | NLP-based emotion prediction |
| ğŸ“· Facial Emotion Detection | CNN-based webcam analysis |
| ğŸ§  Dual AI Pipeline | Combines ML + DL techniques |
| ğŸ§¾ Prediction History | Tracks all past detections |
| ğŸ§¹ Clear Button | Clears log instantly |
| ğŸŒ— Dark/Light Mode | Theme toggle |
| ğŸ¨ Modern UI | Sky-blue gradient with glassmorphism |
| ğŸ’» Laptop Friendly | Responsive layout for 13â€“15" screens |

---

## ğŸ§° 6. Technologies Used

| Category | Tools |
|-----------|-------|
| **Language** | Python 3 |
| **ML/DL** | TensorFlow, Keras, scikit-learn |
| **CV/NLP** | OpenCV, TF/Keras, Joblib |
| **Data Handling** | Pandas, NumPy |
| **Frontend** | HTML, CSS, JavaScript |
| **Server** | Python `http.server` |
| **Visualization** | Matplotlib, custom JS progress bars |

---

## ğŸ¤ 7. Contributing Guidelines

Contributions are welcome! ğŸ‰  

1. Fork the repo  
2. Create a new branch (`feature-name`)  
3. Commit your changes  
4. Push and open a Pull Request  

You can also:
- ğŸ Report issues  
- ğŸ’¡ Suggest new features  
- ğŸ§  Improve UI/UX  

---

## ğŸ“œ 8. License

This project is licensed under the **MIT License**.  

```
MIT License Â© 2025 Nagateja Goud
```

---

## ğŸ™Œ 9. Credits

**Developed by:** [Nagateja Goud](#)  

**Datasets:**
- FER-2013 (Kaggle)
- Text Emotion Dataset (Kaggle NLP Dataset)

**Libraries Used:**
TensorFlow â€¢ scikit-learn â€¢ OpenCV â€¢ NumPy â€¢ Pandas â€¢ Joblib  

---

## ğŸ“© 10. Contact Information

ğŸ’» **GitHub:** [github.com/nagateja8185](https://github.com/nagateja8185)  
ğŸŒ **LinkedIn:** [linkedin.com/in/thimmapur-nagateja-goud8185](www.linkedin.com/in/thimmapur-nagateja-goud8185)

---

## ğŸ› Known Issues

- Low-light webcam conditions may reduce facial accuracy.  
- Webcam capture rate depends on browser permissions.  
- Dataset imbalance can affect emotion confidence.  

---

## ğŸš€ Future Plans

- ğŸ¤ Add **Voice Emotion Recognition (audio)**  
- ğŸ‘¥ Detect multiple faces simultaneously  
- â˜ï¸ Deploy on **Streamlit or WebApp**  
- ğŸ“ˆ Add **live emotion trend charts**  

---

### ğŸ§­ Quick Command Reference

```bash
# Create venv
python -m venv venv

# Activate
venv\Scripts\activate   # (Windows)
source venv/bin/activate  # (Linux/macOS)

# Install dependencies
pip install --upgrade pip
pip install numpy pandas opencv-python matplotlib scikit-learn joblib tensorflow==2.12 pillow Werkzeug aiohttp

# Train models
python src/train_image.py
python src/train_text.py

# Start backend server
python src/multimodal_server.py

# Open in browser
http://localhost:8000
```

---

â­ **If you found this project useful, please give it a star on GitHub!** ğŸŒŸ
